{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# reading the data\n",
    "bangalore = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning//bangalore_cars.xlsx')\n",
    "bangalore['City'] = 'Bangalore'\n",
    "chennai = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning//chennai_cars.xlsx')\n",
    "chennai['City'] = 'Chennai'\n",
    "delhi = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning//delhi_cars.xlsx')\n",
    "delhi['City'] = 'Delhi'\n",
    "hyderabad = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning\\\\hyderabad_cars.xlsx')\n",
    "hyderabad['City'] = 'Hyderabad'\n",
    "jaipur = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning//jaipur_cars.xlsx')\n",
    "jaipur['City'] = 'Jaipur'\n",
    "kolkata = pd.read_excel('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Data Preprocessing & Cleaning//kolkata_cars.xlsx')\n",
    "kolkata['City'] = 'Kolkata'\n",
    "\n",
    "# concatenating all the data\n",
    "all_city_df = pd.concat([bangalore,chennai,delhi,hyderabad,jaipur,kolkata],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first 4 rows of the dataframe\n",
    "all_city_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the columns of the dataframe\n",
    "all_city_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of rows in the dataframe\n",
    "all_city_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the new_car_detail column\n",
    "car_details = all_city_df['new_car_detail'].apply(lambda x : ast.literal_eval(x))\n",
    "# normalizing the json data\n",
    "df1 = pd.json_normalize(car_details)\n",
    "# renaming the columns\n",
    "df1.rename(columns={'it':'Ignition type','ft':'Fuel type','bt':'Body type','km':'Kilometers driven','owner':'Ownership details','mileage':'car_mileage','engine':'car_engine',},inplace=True)\n",
    "df1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the new_car_overview column\n",
    "car_overview = all_city_df['new_car_overview'].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "# getting the top values from the car_overview column\n",
    "top = car_overview.apply(lambda x : x['top'])\n",
    "rows = []\n",
    "\n",
    "# looping through the top values and appending the data to the rows list\n",
    "for i in top:\n",
    "    column_data = {}\n",
    "    for j in i:                                 # looping through the data\n",
    "        column_data[j['key']] = j['value']      # appending the data to the column_data dictionary\n",
    "    rows.append(column_data)                    # appending the column_data dictionary to the rows list\n",
    "\n",
    "# creating a dataframe from the rows list\n",
    "df2 = pd.DataFrame(rows)\n",
    "df2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the new_car_specs column\n",
    "car_specs = all_city_df['new_car_specs'].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "l = []                                      # creating an empty list\n",
    "for i in car_specs:                         # looping through the car_specs column\n",
    "    column_data = {}                        # creating an empty dictionary\n",
    "    for j in i['top']:                      # looping through the top values\n",
    "        column_data[j['key']] = j['value']  # appending the data to the column_data dictionary\n",
    "    l.append(column_data)                   # appending the column_data dictionary to the list\n",
    "\n",
    "# creating a dataframe from the list\n",
    "df4 = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(4)                            # printing the first 4 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data = {}                                        # creating an empty dictionary\n",
    "data = [j for i in car_specs for j in i['data']]        # looping through the data column\n",
    "l = []                                                  # creating an empty list\n",
    "\n",
    "# looping through the data column\n",
    "for i in data:                                          \n",
    "    column_data = {}                                    # creating an empty dictionary\n",
    "    x = i['subHeading']                                 # getting the subHeading value\n",
    "    for j in i['list']:                                 # looping through the list values\n",
    "        column_data[f\"{x}_{j['key']}\"] = j['value']     # appending the data to the column_data dictionary\n",
    "    l.append(column_data)                               # appending the column_data dictionary to the list\n",
    "\n",
    "# creating a dataframe from the list\n",
    "df5 = pd.DataFrame(l)\n",
    "df5.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the df4 and df5 dataframe\n",
    "df4 = pd.concat([df4,df5],axis=1)       \n",
    "df4.head(4)                        # printing the first 4 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all the dataframes\n",
    "df = pd.concat([df1,df2,df4],axis=1)                \n",
    "df['City'] = all_city_df['City']                      # adding the City column to the dataframe\n",
    "df.head(4)                                         # printing the first 4 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns  \n",
    "\n",
    "df.drop(['Ignition type','oem','priceActual','priceSaving','priceFixedText','trendingText.desc','trendingText.heading','trendingText.imgUrl','Fuel Type','Kms Driven','RTO','Ownership','Transmission','Year of Manufacture','Engine Displacement','Dimensions_Ground Clearance Unladen','Miscellaneous_Alloy Wheel Size','Miscellaneous_Cargo Volumn','Engine_Super Charger', 'Dimensions_Length', 'Dimensions_Width', 'Dimensions_Height', 'Dimensions_Wheel Base', 'Dimensions_Front Tread', 'Dimensions_Rear Tread', 'Dimensions_Kerb Weight', 'Dimensions_Gross Weight', 'Miscellaneous_Gear Box', 'Miscellaneous_Drive Type', 'Miscellaneous_Seating Capacity', 'Miscellaneous_Steering Type', 'Miscellaneous_Turning Radius', 'Miscellaneous_Front Brake Type', 'Miscellaneous_Rear Brake Type', 'Miscellaneous_Top Speed', 'Miscellaneous_Acceleration', 'Miscellaneous_Tyre Type', 'Miscellaneous_No Door Numbers', 'Seats', 'Wheel Size', 'Engine_Color', 'Engine_Engine Type', 'Engine_Displacement', 'Engine_Max Power', 'Engine_Max Torque', 'Engine_No of Cylinder', 'Engine_Values per Cylinder', 'Engine_Value Configuration', 'Engine_Fuel Suppy System', 'Engine_BoreX Stroke', 'Engine_Compression Ratio', 'Engine_Turbo Charger'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4) # printing the first 4 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardising Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of missing values in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nAfter removing the rows where all columns have null values\")\n",
    "\n",
    "# Drop rows where all columns have null values in a row\n",
    "df = df.dropna(how='all',axis=0)\n",
    "df.isnull().sum() # counting the number of rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the currency symbol and spaces from Kilometers driven column\n",
    "def km_driven(x):\n",
    "    year = x.replace(' km','').replace(',','')\n",
    "    return int(year)\n",
    "# Remove the currency symbol and spaces\n",
    "df['Kilometers driven'] = df['Kilometers driven'].apply(km_driven)\n",
    "df['Kilometers driven'] = df['Kilometers driven'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the columns to string\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# Function to convert price to numerical value\n",
    "def convert_price(price_str):\n",
    "    if isinstance(price_str, str):\n",
    "        price_str = price_str.replace(\"â‚¹\", \"\").strip()\n",
    "        if \"Lakh\" in price_str:\n",
    "            price_str = price_str.replace(\"Lakh\", \"\").strip()\n",
    "            return float(float(price_str) * 100000)  # 1 Lakh = 100,000\n",
    "        elif \"Cr\" in price_str:\n",
    "            price_str = price_str.replace(\"Crore\", \"\").strip()\n",
    "            return float(float(price_str) * 10000000)  # 1 Cr = 10,000,000\n",
    "# Apply the function to the 'price' column\n",
    "df['price'] = df['price'].apply(convert_price).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re       # importing the re module\n",
    "\n",
    "# function to extract the year from the Registration Year column\n",
    "def year(x):\n",
    "    if isinstance(x, str):\n",
    "        pattern = r'\\d{4}'                  # pattern to extract the year\n",
    "        match = re.search(pattern, x)       # searching the pattern in the string\n",
    "        if match:                           # if the pattern is found return the matched value\n",
    "            return int(match.group(0))\n",
    "\n",
    "df['Registration Year'] = df['Registration Year'].apply(year).astype('Int64')   # applying the function to the Registration Year column\n",
    "\n",
    "# renaming the columns\n",
    "df.rename(columns={'Mileage':'Mileage(kmpl)','Engine': 'Engine(CC)','Max Power':'Max Power(bhp)','Torque':'Torque(Nm)'},inplace=True)   \n",
    "\n",
    "def mileage(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return float(x.replace(' km/kg', '')) * 0.425143707         # 1 km/kg = 0.425143707 kmpl\n",
    "        except:\n",
    "            return float(x.replace(' kmpl', ''))                        # removing the kmpl from the string\n",
    "\n",
    "def get_values(x):\n",
    "    if isinstance(x, str):\n",
    "        pattern = r'\\d*\\.\\d+|\\d+'                       # pattern to extract the values\n",
    "        return re.findall(pattern, x)[0]                # returning the first value from the list\n",
    "\n",
    "# applying the functions to the columns\n",
    "df['Mileage(kmpl)'] = df['Mileage(kmpl)'].apply(mileage).astype('float64',errors='ignore')\n",
    "df['Engine(CC)'] = df['Engine(CC)'].apply(get_values).astype('float64',errors='ignore')\n",
    "df['Max Power(bhp)'] = df['Max Power(bhp)'].apply(get_values).astype('float64',errors='ignore')\n",
    "df['Torque(Nm)'] = df['Torque(Nm)'].apply(get_values).astype('float64',errors='ignore')\n",
    "\n",
    "df.dtypes # printing the datatypes of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values using fillna method \n",
    "df['price'].fillna(df['price'].mean(), inplace=True)    \n",
    "df['Registration Year'].fillna(df['Registration Year'].median(), inplace=True)\n",
    "df['Insurance Validity'].fillna(df['Insurance Validity'].mode()[0], inplace=True)\n",
    "df['Mileage(kmpl)'].fillna(df['Mileage(kmpl)'].mean(), inplace=True)\n",
    "df['Engine(CC)'].fillna(df['Engine(CC)'].mean(), inplace=True)\n",
    "df['Max Power(bhp)'].fillna(df['Max Power(bhp)'].mean(), inplace=True)\n",
    "df['Torque(Nm)'].fillna(df['Torque(Nm)'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # counting the number of missing values in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder    # importing the LabelEncoder class\n",
    "\n",
    "# columns to encode\n",
    "columns_to_encode = ['Fuel type','Body type','transmission','Ownership details','model','variantName','Insurance Validity','City']  \n",
    "\n",
    "# Apply label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "df.head(2) # printing the first 2 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler    # importing the MinMaxScaler class\n",
    "from sklearn.preprocessing import StandardScaler    # importing the StandardScaler class\n",
    "\n",
    "# columns to scale\n",
    "columns_to_scale = ['price','Kilometers driven','modelYear','Registration Year','Mileage(kmpl)','Engine(CC)','Max Power(bhp)','Torque(Nm)']\n",
    "\n",
    "df_minmax = df_standard = df.copy()                     # creating a copy of the dataframe\n",
    "\n",
    "# Apply MinMaxScaler by creating an object of MinMaxScaler class\n",
    "scaler = MinMaxScaler()                                \n",
    "df_minmax[columns_to_scale] = scaler.fit_transform(df_minmax[columns_to_scale])   # scaling the columns\n",
    "\n",
    "# Apply StandardScaler by creating an object of StandardScaler class\n",
    "scaler = StandardScaler()                                      \n",
    "df_standard[columns_to_scale] = scaler.fit_transform(df_standard[columns_to_scale])    # scaling the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore    # importing the zscore function\n",
    "import numpy as np                # importing the numpy library \n",
    "\n",
    "# function to remove outliers\n",
    "def remove_outliers(df, columns):\n",
    "    z = np.abs(zscore(df[columns]))\n",
    "    # Keep only rows where Z-score is less than 3\n",
    "    df = df[(z < 3).all(axis=1)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers using Z-score\n",
    "df_minmax = remove_outliers(df_minmax, columns_to_scale)\n",
    "df_standard = remove_outliers(df_standard, columns_to_scale)  \n",
    "\n",
    "if df_minmax.equals(df_standard):    # checking if the dataframes are equal\n",
    "    print(\"Dataframes are equal\")   # printing the message\n",
    "    df_minmax.to_excel('all_city.xlsx',index=False)    # saving the dataframe to an excel file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
