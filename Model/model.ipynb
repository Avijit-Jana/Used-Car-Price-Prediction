{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# reading the data from the file\n",
    "df = pd.read_excel('Data Preprocessing & Cleaning\\\\all_city.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)         # features\n",
    "y = df['price']                     # target\n",
    "\n",
    "# splitting the data into training and testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# dictionary of models to be used for training\n",
    "models = {  \n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Linear Regression: 0.7243 (R^2)\n",
      "Decision Tree: 0.8495 (R^2)\n",
      "Random Forest: 0.9197 (R^2)\n",
      "Gradient Boosting: 0.9010 (R^2)\n"
     ]
    }
   ],
   "source": [
    "# Model Training with Cross-validation\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    results[name] = scores.mean()\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "for model_name, cv_score in results.items():\n",
    "    print(f\"{model_name}: {cv_score:.4f} (R^2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.170897</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.682230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.101030</td>\n",
       "      <td>0.038613</td>\n",
       "      <td>0.849813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>0.023220</td>\n",
       "      <td>0.909686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>0.031671</td>\n",
       "      <td>0.876817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model       MAE       MSE  R2 Score\n",
       "0            Linear Regression  0.170897  0.081699  0.682230\n",
       "1      Decision Tree Regressor  0.101030  0.038613  0.849813\n",
       "2      Random Forest Regressor  0.077540  0.023220  0.909686\n",
       "3  Gradient Boosting Regressor  0.096155  0.031671  0.876817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the models based on evaluation metrics to select the best performing model\n",
    "models = ['Linear Regression', 'Decision Tree Regressor', 'Random Forest Regressor', 'Gradient Boosting Regressor']\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "dt = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "gb = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "mae = [mean_absolute_error(y_test, lr.predict(X_test)),\n",
    "    mean_absolute_error(y_test, dt.predict(X_test)),\n",
    "    mean_absolute_error(y_test, rf.predict(X_test)),\n",
    "    mean_absolute_error(y_test, gb.predict(X_test))]\n",
    "\n",
    "mse = [mean_squared_error(y_test, lr.predict(X_test)),\n",
    "    mean_squared_error(y_test, dt.predict(X_test)),\n",
    "    mean_squared_error(y_test, rf.predict(X_test)),\n",
    "    mean_squared_error(y_test, gb.predict(X_test))]\n",
    "\n",
    "r2 = [r2_score(y_test, lr.predict(X_test)),\n",
    "      r2_score(y_test, dt.predict(X_test)),\n",
    "      r2_score(y_test, rf.predict(X_test)),\n",
    "      r2_score(y_test, gb.predict(X_test))]\n",
    "\n",
    "comparison_df = pd.DataFrame({'Model': models, 'MAE': mae, 'MSE': mse, 'R2 Score': r2})\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After comparing the models, we can see that the Random Forest Regressor has the best performance based on the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
      "Best Parameters: {'n_estimators': np.int64(120), 'min_samples_split': np.int64(4), 'min_samples_leaf': np.int64(1), 'max_depth': 50, 'bootstrap': True}\n",
      "Best Score: 0.9164568512939335\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 201, 10),         # Number of trees in random forest\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],        # Maximum number of levels in tree\n",
    "    'min_samples_split': np.arange(2, 11),          # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': np.arange(1, 5),            # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]                      # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(), param_distributions=param_dist, n_iter=20, cv=4, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9113738019589291\n",
      "MSE: 0.02278602573616842\n"
     ]
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(n_estimators=120, min_samples_split=4, \n",
    "                                 min_samples_leaf=1, max_depth=50, \n",
    "                                 bootstrap=True,random_state=42)\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model in a pickle file\n",
    "import pickle\n",
    "with open('D:\\\\Programming\\\\GUVI PROJECTS CODE\\\\PROJECT - 3\\\\Model\\\\model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
